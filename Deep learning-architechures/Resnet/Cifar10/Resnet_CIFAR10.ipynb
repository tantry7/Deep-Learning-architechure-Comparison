{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet-CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrBzaefmts2x"
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
        "epochs = 50 \n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmoX7j59uEWO",
        "outputId": "028eb2e4-e551-4105-9d2a-a45afe14c626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nU59ctSuNqH"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow"
      ],
      "metadata": {
        "id": "CvV-lPxCPZ4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyjB9icGthBJ",
        "outputId": "8b69438b-8b1d-4bac-d990-54e885c376d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tensorflow.keras.optimizers.Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 32, 32, 16)   448         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 32, 32, 16)  64          ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 32, 32, 16)  64          ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 32, 32, 16)  64          ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 32, 16)   0           ['activation_19[0][0]',          \n",
            "                                                                  'batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 32, 32, 16)   0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 32, 32, 16)  64          ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 32, 32, 16)  64          ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 32, 32, 16)   0           ['activation_21[0][0]',          \n",
            "                                                                  'batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 32, 32, 16)   0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 32, 32, 16)  64          ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 32, 32, 16)  64          ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 32, 32, 16)   0           ['activation_23[0][0]',          \n",
            "                                                                  'batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 32, 32, 16)   0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 32)   4640        ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 16, 16, 32)  128         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 32)   544         ['activation_25[0][0]']          \n",
            "                                                                                                  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " batch_normalization_27 (BatchN  (None, 16, 16, 32)  128         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 16, 16, 32)   0           ['conv2d_30[0][0]',              \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 32)   0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 32)  128         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 16, 16, 32)  128         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 16, 16, 32)   0           ['activation_27[0][0]',          \n",
            "                                                                  'batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 16, 16, 32)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 16, 16, 32)  128         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 16, 16, 32)  128         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 16, 16, 32)   0           ['activation_29[0][0]',          \n",
            "                                                                  'batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 16, 16, 32)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 8, 8, 64)     18496       ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 8, 8, 64)    256         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 8, 8, 64)     2112        ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 8, 8, 64)    256         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 8, 8, 64)     0           ['conv2d_37[0][0]',              \n",
            "                                                                  'batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 8, 8, 64)     0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 8, 8, 64)    256         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 8, 8, 64)    256         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 8, 8, 64)     0           ['activation_33[0][0]',          \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 8, 8, 64)     0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 8, 8, 64)    256         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 8, 8, 64)    256         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 8, 8, 64)     0           ['activation_35[0][0]',          \n",
            "                                                                  'batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 8, 8, 64)     0           ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 1, 1, 64)    0           ['activation_37[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 64)           0           ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           650         ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:97: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.5695 - accuracy: 0.4876WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 47s 26ms/step - loss: 1.5693 - accuracy: 0.4876 - val_loss: 1.5311 - val_accuracy: 0.5167 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.1766 - accuracy: 0.6376WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.1763 - accuracy: 0.6376 - val_loss: 1.3357 - val_accuracy: 0.6118 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 1.0156 - accuracy: 0.7041WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.0158 - accuracy: 0.7041 - val_loss: 1.1868 - val_accuracy: 0.6541 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.9305 - accuracy: 0.7347WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.9306 - accuracy: 0.7346 - val_loss: 1.1128 - val_accuracy: 0.6960 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.8641 - accuracy: 0.7602WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.8640 - accuracy: 0.7602 - val_loss: 0.8331 - val_accuracy: 0.7723 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.8206 - accuracy: 0.7760WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.8203 - accuracy: 0.7760 - val_loss: 0.9781 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.7854 - accuracy: 0.7889WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.7856 - accuracy: 0.7889 - val_loss: 1.0049 - val_accuracy: 0.7140 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.7530 - accuracy: 0.8007WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.7530 - accuracy: 0.8007 - val_loss: 0.8066 - val_accuracy: 0.7859 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.7318 - accuracy: 0.8092WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.7318 - accuracy: 0.8091 - val_loss: 0.8225 - val_accuracy: 0.7779 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.7078 - accuracy: 0.8196WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7079 - accuracy: 0.8195 - val_loss: 0.8673 - val_accuracy: 0.7670 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.6918 - accuracy: 0.8245WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6916 - accuracy: 0.8246 - val_loss: 0.9156 - val_accuracy: 0.7547 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/50\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.8328WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6728 - accuracy: 0.8329 - val_loss: 0.8386 - val_accuracy: 0.7835 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.6607 - accuracy: 0.8374WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6607 - accuracy: 0.8375 - val_loss: 0.7786 - val_accuracy: 0.8070 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 14/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.6497 - accuracy: 0.8401WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6495 - accuracy: 0.8402 - val_loss: 0.8858 - val_accuracy: 0.7764 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.6428 - accuracy: 0.8436WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6427 - accuracy: 0.8436 - val_loss: 0.9547 - val_accuracy: 0.7622 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.6310 - accuracy: 0.8490WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6310 - accuracy: 0.8490 - val_loss: 0.7861 - val_accuracy: 0.8120 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.6227 - accuracy: 0.8532WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6225 - accuracy: 0.8532 - val_loss: 0.8240 - val_accuracy: 0.7961 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/50\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.6204 - accuracy: 0.8540WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6204 - accuracy: 0.8540 - val_loss: 0.8390 - val_accuracy: 0.7866 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 19/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.6112 - accuracy: 0.8561WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6112 - accuracy: 0.8561 - val_loss: 0.8135 - val_accuracy: 0.8058 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.8598WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6012 - accuracy: 0.8598 - val_loss: 0.9594 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.8610WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5992 - accuracy: 0.8610 - val_loss: 0.7716 - val_accuracy: 0.8083 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 22/50\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5932 - accuracy: 0.8642WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5932 - accuracy: 0.8642 - val_loss: 0.8203 - val_accuracy: 0.8091 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 23/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5854 - accuracy: 0.8671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5853 - accuracy: 0.8672 - val_loss: 0.6625 - val_accuracy: 0.8426 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 24/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.5785 - accuracy: 0.8683WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5788 - accuracy: 0.8683 - val_loss: 0.7179 - val_accuracy: 0.8296 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.8697WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5788 - accuracy: 0.8697 - val_loss: 0.8313 - val_accuracy: 0.8057 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 26/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5708 - accuracy: 0.8716WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5709 - accuracy: 0.8715 - val_loss: 0.7181 - val_accuracy: 0.8344 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 27/50\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.5700 - accuracy: 0.8720WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5696 - accuracy: 0.8722 - val_loss: 0.7571 - val_accuracy: 0.8233 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.8740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5633 - accuracy: 0.8740 - val_loss: 0.8505 - val_accuracy: 0.7989 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.8738WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5680 - accuracy: 0.8738 - val_loss: 0.9407 - val_accuracy: 0.7751 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.8761WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5628 - accuracy: 0.8761 - val_loss: 0.7610 - val_accuracy: 0.8221 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 31/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.5571 - accuracy: 0.8779WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5570 - accuracy: 0.8779 - val_loss: 0.8051 - val_accuracy: 0.8181 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 32/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5534 - accuracy: 0.8798WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5533 - accuracy: 0.8798 - val_loss: 0.7171 - val_accuracy: 0.8367 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.8804WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5548 - accuracy: 0.8804 - val_loss: 0.7541 - val_accuracy: 0.8222 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 34/50\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5497 - accuracy: 0.8814WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5496 - accuracy: 0.8815 - val_loss: 0.7258 - val_accuracy: 0.8316 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 35/50\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.5518 - accuracy: 0.8804WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5521 - accuracy: 0.8803 - val_loss: 0.7621 - val_accuracy: 0.8231 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 36/50\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5451 - accuracy: 0.8834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5450 - accuracy: 0.8835 - val_loss: 0.8000 - val_accuracy: 0.8115 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 37/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5494 - accuracy: 0.8806WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5496 - accuracy: 0.8805 - val_loss: 0.6907 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 38/50\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.5384 - accuracy: 0.8849WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5383 - accuracy: 0.8849 - val_loss: 0.8426 - val_accuracy: 0.8046 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 39/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.8850WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5381 - accuracy: 0.8850 - val_loss: 0.7030 - val_accuracy: 0.8422 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 40/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5358 - accuracy: 0.8847WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.5357 - accuracy: 0.8847 - val_loss: 0.6893 - val_accuracy: 0.8487 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 41/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5326 - accuracy: 0.8867WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5328 - accuracy: 0.8866 - val_loss: 0.6837 - val_accuracy: 0.8447 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 42/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.8860WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5327 - accuracy: 0.8861 - val_loss: 0.7237 - val_accuracy: 0.8357 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 43/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.5322 - accuracy: 0.8873WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5321 - accuracy: 0.8874 - val_loss: 0.6548 - val_accuracy: 0.8567 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 44/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.8882WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.5285 - accuracy: 0.8881 - val_loss: 0.7459 - val_accuracy: 0.8286 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.8887WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5302 - accuracy: 0.8887 - val_loss: 1.0227 - val_accuracy: 0.7688 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 46/50\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5293 - accuracy: 0.8884WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5293 - accuracy: 0.8884 - val_loss: 0.8569 - val_accuracy: 0.7926 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 47/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.5260 - accuracy: 0.8889WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5261 - accuracy: 0.8888 - val_loss: 0.6623 - val_accuracy: 0.8498 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 48/50\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5202 - accuracy: 0.8920WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5203 - accuracy: 0.8919 - val_loss: 0.7456 - val_accuracy: 0.8333 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 49/50\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5247 - accuracy: 0.8917WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5247 - accuracy: 0.8917 - val_loss: 0.7398 - val_accuracy: 0.8256 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 50/50\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.5179 - accuracy: 0.8928WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5183 - accuracy: 0.8926 - val_loss: 0.7278 - val_accuracy: 0.8337 - lr: 0.0010\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.7278 - accuracy: 0.8337\n",
            "Test loss: 0.7278314232826233\n",
            "Test accuracy: 0.8337000012397766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEKw3x28tmgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aee6384-70ff-48a4-accb-7734061802cf"
      },
      "source": [
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7278314232826233, 0.8337000012397766]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2hQOj6luyGu",
        "outputId": "3c8088e2-96f3-46e8-8ce9-e4cfb4e30960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"val\"],loc=\"upper left\")\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title(\"model acc\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"val\"],loc=\"upper left\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "iY_CipahrwFi",
        "outputId": "8a930cd3-66f7-4dd6-ff3a-8992c04928da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ac8326e7ddbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title(\"model Accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend([\"train\",\"val\"],loc=\"upper right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fb7iFdbVr6oh",
        "outputId": "68869332-6699-4033-867d-15a1a8f3cb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iOu52DAkAtSn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}